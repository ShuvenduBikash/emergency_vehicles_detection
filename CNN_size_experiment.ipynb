{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "V95Uwl8F2u_S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "teiwDTpF6Eq8"
   },
   "source": [
    "# Training with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ckDWqMjk4yBE"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from keras import losses, optimizers, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1518622287177,
     "user": {
      "displayName": "Shuvendu Bikash",
      "photoUrl": "//lh6.googleusercontent.com/-qmLdelcDhNY/AAAAAAAAAAI/AAAAAAAAOyw/0BejXT-_QPo/s50-c-k-no/photo.jpg",
      "userId": "106434026064423574094"
     },
     "user_tz": -360
    },
    "id": "hbfMDbq26Gs3",
    "outputId": "3261ea97-1c67-4d80-acdd-7bc359614fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9410 images belonging to 2 classes.\n",
      "Found 366 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 29, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 351,618\n",
      "Trainable params: 351,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 124s 849ms/step - loss: 0.4419 - acc: 0.8634 - val_loss: 0.6536 - val_acc: 0.7460\n",
      "Epoch 2/50\n",
      " 36/146 [======>.......................] - ETA: 1:19 - loss: 0.4578 - acc: 0.8351"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 124s 846ms/step - loss: 0.4152 - acc: 0.8508 - val_loss: 0.5339 - val_acc: 0.7358\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 34s 232ms/step - loss: 0.3450 - acc: 0.8624 - val_loss: 0.4149 - val_acc: 0.7724\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 31s 214ms/step - loss: 0.2969 - acc: 0.8778 - val_loss: 0.3154 - val_acc: 0.8548\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 33s 225ms/step - loss: 0.2606 - acc: 0.9005 - val_loss: 0.2912 - val_acc: 0.8902\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 32s 217ms/step - loss: 0.2099 - acc: 0.9227 - val_loss: 0.3315 - val_acc: 0.8537\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 33s 225ms/step - loss: 0.1971 - acc: 0.9306 - val_loss: 0.2404 - val_acc: 0.9032\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.1659 - acc: 0.9443 - val_loss: 0.1981 - val_acc: 0.9187\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 32s 216ms/step - loss: 0.1654 - acc: 0.9424 - val_loss: 0.2549 - val_acc: 0.8780\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.1458 - acc: 0.9512 - val_loss: 0.1881 - val_acc: 0.9274\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 34s 233ms/step - loss: 0.1411 - acc: 0.9529 - val_loss: 0.2029 - val_acc: 0.9228\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 32s 220ms/step - loss: 0.1461 - acc: 0.9452 - val_loss: 0.2215 - val_acc: 0.8984\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.1285 - acc: 0.9561 - val_loss: 0.1564 - val_acc: 0.9234\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 31s 210ms/step - loss: 0.1264 - acc: 0.9525 - val_loss: 0.2426 - val_acc: 0.9146\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 32s 223ms/step - loss: 0.1376 - acc: 0.9512 - val_loss: 0.1668 - val_acc: 0.9268\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 35s 242ms/step - loss: 0.1197 - acc: 0.9578 - val_loss: 0.2722 - val_acc: 0.8831\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 31s 215ms/step - loss: 0.1028 - acc: 0.9630 - val_loss: 0.1356 - val_acc: 0.9431\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.1190 - acc: 0.9557 - val_loss: 0.2347 - val_acc: 0.8902\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 32s 219ms/step - loss: 0.1051 - acc: 0.9619 - val_loss: 0.1911 - val_acc: 0.9234\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.1078 - acc: 0.9604 - val_loss: 0.1587 - val_acc: 0.9472\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 32s 219ms/step - loss: 0.1270 - acc: 0.9480 - val_loss: 0.1647 - val_acc: 0.9309\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 30s 207ms/step - loss: 0.1020 - acc: 0.9664 - val_loss: 0.1659 - val_acc: 0.9355\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0938 - acc: 0.9677 - val_loss: 0.1223 - val_acc: 0.9634\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 34s 235ms/step - loss: 0.0969 - acc: 0.9655 - val_loss: 0.1487 - val_acc: 0.9593\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 34s 232ms/step - loss: 0.0933 - acc: 0.9673 - val_loss: 0.2076 - val_acc: 0.9274\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 32s 216ms/step - loss: 0.0884 - acc: 0.9685 - val_loss: 0.1647 - val_acc: 0.9309\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 31s 211ms/step - loss: 0.0927 - acc: 0.9660 - val_loss: 0.1662 - val_acc: 0.9512\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0893 - acc: 0.9673 - val_loss: 0.0874 - val_acc: 0.9677\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0896 - acc: 0.9683 - val_loss: 0.2379 - val_acc: 0.9106\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 31s 214ms/step - loss: 0.0826 - acc: 0.9694 - val_loss: 0.1385 - val_acc: 0.9512\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 31s 213ms/step - loss: 0.0935 - acc: 0.9632 - val_loss: 0.1226 - val_acc: 0.9556\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0834 - acc: 0.9705 - val_loss: 0.1773 - val_acc: 0.9431\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 31s 213ms/step - loss: 0.0853 - acc: 0.9655 - val_loss: 0.1585 - val_acc: 0.9309\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 32s 217ms/step - loss: 0.0938 - acc: 0.9640 - val_loss: 0.1315 - val_acc: 0.9556\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 30s 209ms/step - loss: 0.0742 - acc: 0.9756 - val_loss: 0.1225 - val_acc: 0.9634\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 32s 219ms/step - loss: 0.0751 - acc: 0.9724 - val_loss: 0.1995 - val_acc: 0.9309\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 32s 219ms/step - loss: 0.0827 - acc: 0.9720 - val_loss: 0.1153 - val_acc: 0.9677\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0773 - acc: 0.9732 - val_loss: 0.1102 - val_acc: 0.9512\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0746 - acc: 0.9722 - val_loss: 0.1632 - val_acc: 0.9512\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 35s 239ms/step - loss: 0.0766 - acc: 0.9754 - val_loss: 0.1608 - val_acc: 0.9476\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 35s 241ms/step - loss: 0.0690 - acc: 0.9750 - val_loss: 0.1348 - val_acc: 0.9553\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 34s 230ms/step - loss: 0.0739 - acc: 0.9728 - val_loss: 0.0977 - val_acc: 0.9756\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 33s 225ms/step - loss: 0.0674 - acc: 0.9769 - val_loss: 0.1384 - val_acc: 0.9435\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 33s 227ms/step - loss: 0.0633 - acc: 0.9771 - val_loss: 0.1107 - val_acc: 0.9553\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 31s 213ms/step - loss: 0.0667 - acc: 0.9750 - val_loss: 0.1479 - val_acc: 0.9431\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 34s 230ms/step - loss: 0.0704 - acc: 0.9762 - val_loss: 0.1384 - val_acc: 0.9634\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0580 - acc: 0.9795 - val_loss: 0.1505 - val_acc: 0.9395\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 34s 234ms/step - loss: 0.0670 - acc: 0.9769 - val_loss: 0.1277 - val_acc: 0.9472\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 36s 249ms/step - loss: 0.0572 - acc: 0.9801 - val_loss: 0.1211 - val_acc: 0.9512\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 33s 227ms/step - loss: 0.0556 - acc: 0.9801 - val_loss: 0.0621 - val_acc: 0.9839\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir = 'data\\\\train'\n",
    "test_dir = 'data\\\\test'\n",
    "\n",
    "dim = 64\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim, dim, 3)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 146,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1037,
     "output_extras": [
      {
       "item_id": 52
      },
      {
       "item_id": 104
      },
      {
       "item_id": 152
      },
      {
       "item_id": 195
      },
      {
       "item_id": 238
      },
      {
       "item_id": 286
      },
      {
       "item_id": 333
      },
      {
       "item_id": 366
      },
      {
       "item_id": 398
      },
      {
       "item_id": 442
      },
      {
       "item_id": 486
      },
      {
       "item_id": 528
      },
      {
       "item_id": 578
      },
      {
       "item_id": 613
      },
      {
       "item_id": 643
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 458294,
     "status": "ok",
     "timestamp": 1518622751496,
     "user": {
      "displayName": "Shuvendu Bikash",
      "photoUrl": "//lh6.googleusercontent.com/-qmLdelcDhNY/AAAAAAAAAAI/AAAAAAAAOyw/0BejXT-_QPo/s50-c-k-no/photo.jpg",
      "userId": "106434026064423574094"
     },
     "user_tz": -360
    },
    "id": "T9gPtISE6kpg",
    "outputId": "c44a04fd-8422-424a-c244-42bd6f7d9c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9410 images belonging to 2 classes.\n",
      "Found 366 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 348, 348, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 174, 174, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 172, 172, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 86, 86, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 84, 84, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 42, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 112896)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               14450816  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 14,507,394\n",
      "Trainable params: 14,507,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 51/146 [=========>....................] - ETA: 32s - loss: 0.4135 - acc: 0.8560"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69/146 [=============>................] - ETA: 25s - loss: 0.4110 - acc: 0.8519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 48s 325ms/step - loss: 0.3916 - acc: 0.8521 - val_loss: 0.4101 - val_acc: 0.8226\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 43s 297ms/step - loss: 0.2864 - acc: 0.8883 - val_loss: 0.5183 - val_acc: 0.7642\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 45s 306ms/step - loss: 0.2306 - acc: 0.9195 - val_loss: 0.2652 - val_acc: 0.8780\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 43s 297ms/step - loss: 0.1967 - acc: 0.9317 - val_loss: 0.2264 - val_acc: 0.9113\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 44s 303ms/step - loss: 0.1368 - acc: 0.9521 - val_loss: 0.1911 - val_acc: 0.9187\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 44s 302ms/step - loss: 0.1343 - acc: 0.9523 - val_loss: 0.1831 - val_acc: 0.9268\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 44s 300ms/step - loss: 0.1091 - acc: 0.9643 - val_loss: 0.2393 - val_acc: 0.8992\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 45s 308ms/step - loss: 0.1057 - acc: 0.9640 - val_loss: 0.1235 - val_acc: 0.9512\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 44s 303ms/step - loss: 0.1069 - acc: 0.9630 - val_loss: 0.1501 - val_acc: 0.9472\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 43s 296ms/step - loss: 0.0818 - acc: 0.9737 - val_loss: 0.1618 - val_acc: 0.9355\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 45s 307ms/step - loss: 0.0677 - acc: 0.9784 - val_loss: 0.1558 - val_acc: 0.9390\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 43s 293ms/step - loss: 0.0627 - acc: 0.9788 - val_loss: 0.1552 - val_acc: 0.9350\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 45s 305ms/step - loss: 0.0471 - acc: 0.9865 - val_loss: 0.1242 - val_acc: 0.9476\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 50s 341ms/step - loss: 0.0498 - acc: 0.9839 - val_loss: 0.0951 - val_acc: 0.9675\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 45s 310ms/step - loss: 0.0402 - acc: 0.9884 - val_loss: 0.1340 - val_acc: 0.9350\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 45s 306ms/step - loss: 0.0372 - acc: 0.9895 - val_loss: 0.1222 - val_acc: 0.9435\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 42s 290ms/step - loss: 0.0462 - acc: 0.9880 - val_loss: 0.0850 - val_acc: 0.9634\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 47s 325ms/step - loss: 0.0240 - acc: 0.9966 - val_loss: 0.1368 - val_acc: 0.9350\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 43s 293ms/step - loss: 0.0322 - acc: 0.9917 - val_loss: 0.1123 - val_acc: 0.9435\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 45s 306ms/step - loss: 0.0195 - acc: 0.9964 - val_loss: 0.0893 - val_acc: 0.9634\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 43s 296ms/step - loss: 0.0161 - acc: 0.9976 - val_loss: 0.1068 - val_acc: 0.9593\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 43s 296ms/step - loss: 0.0203 - acc: 0.9951 - val_loss: 0.0891 - val_acc: 0.9637\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 45s 309ms/step - loss: 0.0121 - acc: 0.9989 - val_loss: 0.1390 - val_acc: 0.9472\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 43s 295ms/step - loss: 0.0109 - acc: 0.9987 - val_loss: 0.1215 - val_acc: 0.9472\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 44s 299ms/step - loss: 0.0076 - acc: 0.9998 - val_loss: 0.1139 - val_acc: 0.9597\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 45s 306ms/step - loss: 0.0096 - acc: 0.9981 - val_loss: 0.0690 - val_acc: 0.9797\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 43s 298ms/step - loss: 0.0104 - acc: 0.9981 - val_loss: 0.1295 - val_acc: 0.9390\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 45s 311ms/step - loss: 0.0054 - acc: 0.9996 - val_loss: 0.1209 - val_acc: 0.9435\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 44s 302ms/step - loss: 0.0051 - acc: 0.9998 - val_loss: 0.0942 - val_acc: 0.9553\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 47s 320ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1466 - val_acc: 0.9472\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 46s 312ms/step - loss: 0.0034 - acc: 0.9998 - val_loss: 0.0986 - val_acc: 0.9718\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 46s 314ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9309\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 46s 317ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.1162 - val_acc: 0.9675\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 51s 351ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1505 - val_acc: 0.9476\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 49s 336ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 0.9512\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 48s 331ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1575 - val_acc: 0.9431\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 45s 308ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 0.9556\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 49s 337ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1955 - val_acc: 0.9390\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 46s 318ms/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.2457 - val_acc: 0.9228\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 46s 316ms/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.0979 - val_acc: 0.9677\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 44s 300ms/step - loss: 0.0229 - acc: 0.9923 - val_loss: 0.1329 - val_acc: 0.9512\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 44s 303ms/step - loss: 0.0088 - acc: 0.9972 - val_loss: 0.0561 - val_acc: 0.9797\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 45s 310ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 0.9597\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 43s 296ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9553\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 45s 311ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9593\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 44s 298ms/step - loss: 7.6687e-04 - acc: 1.0000 - val_loss: 0.1687 - val_acc: 0.9390\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 45s 305ms/step - loss: 6.0130e-04 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 0.9556\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 44s 300ms/step - loss: 6.1396e-04 - acc: 1.0000 - val_loss: 0.1391 - val_acc: 0.9553\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 43s 297ms/step - loss: 5.1226e-04 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9593\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 44s 303ms/step - loss: 4.2218e-04 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 0.9637\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir = 'data\\\\train'\n",
    "test_dir = 'data\\\\test'\n",
    "\n",
    "dim = 350\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim, dim, 3)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 146,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9410 images belonging to 2 classes.\n",
      "Found 366 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 46, 46, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 187,778\n",
      "Trainable params: 187,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 48/146 [========>.....................] - ETA: 20s - loss: 0.4914 - acc: 0.8496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 33s 226ms/step - loss: 0.4444 - acc: 0.8587 - val_loss: 0.6482 - val_acc: 0.7177\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 34s 235ms/step - loss: 0.4053 - acc: 0.8532 - val_loss: 0.4852 - val_acc: 0.7439\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 33s 229ms/step - loss: 0.3562 - acc: 0.8583 - val_loss: 0.4292 - val_acc: 0.7724\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 32s 216ms/step - loss: 0.3222 - acc: 0.8682 - val_loss: 0.4217 - val_acc: 0.7661\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 31s 215ms/step - loss: 0.2797 - acc: 0.8945 - val_loss: 0.2910 - val_acc: 0.8577\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 33s 223ms/step - loss: 0.2383 - acc: 0.9103 - val_loss: 0.3892 - val_acc: 0.8130\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 32s 220ms/step - loss: 0.2062 - acc: 0.9259 - val_loss: 0.2903 - val_acc: 0.8710\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 31s 215ms/step - loss: 0.1839 - acc: 0.9364 - val_loss: 0.1856 - val_acc: 0.9309\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.1722 - acc: 0.9386 - val_loss: 0.2195 - val_acc: 0.9309\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 32s 220ms/step - loss: 0.1715 - acc: 0.9373 - val_loss: 0.2126 - val_acc: 0.9073\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 33s 223ms/step - loss: 0.1628 - acc: 0.9384 - val_loss: 0.3217 - val_acc: 0.8659\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 32s 216ms/step - loss: 0.1367 - acc: 0.9506 - val_loss: 0.1453 - val_acc: 0.9390\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 33s 229ms/step - loss: 0.1407 - acc: 0.9493 - val_loss: 0.1916 - val_acc: 0.9274\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 31s 214ms/step - loss: 0.1452 - acc: 0.9439 - val_loss: 0.1607 - val_acc: 0.9268\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.1392 - acc: 0.9506 - val_loss: 0.1694 - val_acc: 0.9431\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.1242 - acc: 0.9553 - val_loss: 0.1873 - val_acc: 0.9153\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 32s 220ms/step - loss: 0.1237 - acc: 0.9559 - val_loss: 0.1522 - val_acc: 0.9553\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 34s 236ms/step - loss: 0.1225 - acc: 0.9578 - val_loss: 0.2775 - val_acc: 0.8984\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 32s 222ms/step - loss: 0.1230 - acc: 0.9536 - val_loss: 0.2078 - val_acc: 0.9032\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 33s 223ms/step - loss: 0.1212 - acc: 0.9576 - val_loss: 0.1285 - val_acc: 0.9472\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.1129 - acc: 0.9570 - val_loss: 0.1712 - val_acc: 0.9309\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 38s 264ms/step - loss: 0.1169 - acc: 0.9576 - val_loss: 0.1571 - val_acc: 0.9476\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 38s 260ms/step - loss: 0.1169 - acc: 0.9580 - val_loss: 0.1887 - val_acc: 0.9187\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 36s 247ms/step - loss: 0.1047 - acc: 0.9621 - val_loss: 0.1591 - val_acc: 0.9431\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 32s 217ms/step - loss: 0.1042 - acc: 0.9621 - val_loss: 0.1269 - val_acc: 0.9597\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 36s 243ms/step - loss: 0.0998 - acc: 0.9645 - val_loss: 0.2105 - val_acc: 0.9024\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 36s 244ms/step - loss: 0.1057 - acc: 0.9632 - val_loss: 0.1000 - val_acc: 0.9634\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 37s 252ms/step - loss: 0.1008 - acc: 0.9670 - val_loss: 0.1525 - val_acc: 0.9395\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 37s 251ms/step - loss: 0.1031 - acc: 0.9636 - val_loss: 0.1629 - val_acc: 0.9431\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 30s 208ms/step - loss: 0.0962 - acc: 0.9675 - val_loss: 0.1149 - val_acc: 0.9675\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.0948 - acc: 0.9640 - val_loss: 0.1284 - val_acc: 0.9556\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 32s 223ms/step - loss: 0.0948 - acc: 0.9675 - val_loss: 0.1752 - val_acc: 0.9309\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 31s 212ms/step - loss: 0.0923 - acc: 0.9700 - val_loss: 0.1016 - val_acc: 0.9797\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 32s 222ms/step - loss: 0.1006 - acc: 0.9617 - val_loss: 0.1341 - val_acc: 0.9516\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 32s 216ms/step - loss: 0.0916 - acc: 0.9651 - val_loss: 0.1127 - val_acc: 0.9512\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 34s 233ms/step - loss: 0.0949 - acc: 0.9677 - val_loss: 0.1145 - val_acc: 0.9634\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 30s 207ms/step - loss: 0.0922 - acc: 0.9690 - val_loss: 0.1297 - val_acc: 0.9556\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 34s 232ms/step - loss: 0.0795 - acc: 0.9730 - val_loss: 0.2268 - val_acc: 0.9106\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 32s 222ms/step - loss: 0.0833 - acc: 0.9700 - val_loss: 0.1210 - val_acc: 0.9431\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0872 - acc: 0.9715 - val_loss: 0.0931 - val_acc: 0.9637\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.0796 - acc: 0.9750 - val_loss: 0.1181 - val_acc: 0.9553\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0827 - acc: 0.9694 - val_loss: 0.1167 - val_acc: 0.9553\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0712 - acc: 0.9765 - val_loss: 0.1502 - val_acc: 0.9516\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 35s 240ms/step - loss: 0.0804 - acc: 0.9715 - val_loss: 0.1238 - val_acc: 0.9472\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 33s 227ms/step - loss: 0.0682 - acc: 0.9775 - val_loss: 0.1184 - val_acc: 0.9593\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 34s 236ms/step - loss: 0.0816 - acc: 0.9724 - val_loss: 0.1096 - val_acc: 0.9593\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0736 - acc: 0.9769 - val_loss: 0.1143 - val_acc: 0.9597\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 34s 230ms/step - loss: 0.0721 - acc: 0.9745 - val_loss: 0.1425 - val_acc: 0.9553\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 33s 226ms/step - loss: 0.0718 - acc: 0.9743 - val_loss: 0.1193 - val_acc: 0.9634\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 31s 211ms/step - loss: 0.0703 - acc: 0.9762 - val_loss: 0.1198 - val_acc: 0.9516\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir = 'data\\\\train'\n",
    "test_dir = 'data\\\\test'\n",
    "\n",
    "dim = 48\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim, dim, 3)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 146,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9410 images belonging to 2 classes.\n",
      "Found 366 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 52, 52, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 26, 26, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               5537920   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 5,594,498\n",
      "Trainable params: 5,594,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 32/146 [=====>........................] - ETA: 26s - loss: 0.4441 - acc: 0.8682"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 37s 256ms/step - loss: 0.4139 - acc: 0.8596 - val_loss: 0.4522 - val_acc: 0.7581\n",
      "Epoch 2/50\n",
      " 71/146 [=============>................] - ETA: 15s - loss: 0.3437 - acc: 0.8548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 35s 237ms/step - loss: 0.3218 - acc: 0.8551 - val_loss: 0.4473 - val_acc: 0.7195\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 36s 244ms/step - loss: 0.2493 - acc: 0.8681 - val_loss: 0.2757 - val_acc: 0.9065\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 35s 238ms/step - loss: 0.1882 - acc: 0.9354 - val_loss: 0.2513 - val_acc: 0.8911\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 36s 245ms/step - loss: 0.1800 - acc: 0.9403 - val_loss: 0.2224 - val_acc: 0.9146\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 34s 233ms/step - loss: 0.1371 - acc: 0.9555 - val_loss: 0.2078 - val_acc: 0.9228\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 35s 237ms/step - loss: 0.1244 - acc: 0.9589 - val_loss: 0.1896 - val_acc: 0.9315\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 34s 234ms/step - loss: 0.1204 - acc: 0.9580 - val_loss: 0.1646 - val_acc: 0.9512\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 35s 238ms/step - loss: 0.1017 - acc: 0.9662 - val_loss: 0.1390 - val_acc: 0.9512\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.1139 - acc: 0.9628 - val_loss: 0.1782 - val_acc: 0.9274\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 35s 237ms/step - loss: 0.0952 - acc: 0.9683 - val_loss: 0.1796 - val_acc: 0.9350\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 34s 233ms/step - loss: 0.0821 - acc: 0.9717 - val_loss: 0.1613 - val_acc: 0.9350\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 35s 241ms/step - loss: 0.0798 - acc: 0.9741 - val_loss: 0.1325 - val_acc: 0.9476\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 33s 229ms/step - loss: 0.0803 - acc: 0.9724 - val_loss: 0.1571 - val_acc: 0.9268\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 33s 226ms/step - loss: 0.0729 - acc: 0.9762 - val_loss: 0.1256 - val_acc: 0.9512\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 36s 244ms/step - loss: 0.0610 - acc: 0.9803 - val_loss: 0.1467 - val_acc: 0.9395\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 35s 241ms/step - loss: 0.0593 - acc: 0.9812 - val_loss: 0.1434 - val_acc: 0.9350\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 34s 230ms/step - loss: 0.0581 - acc: 0.9799 - val_loss: 0.1650 - val_acc: 0.9268\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 34s 232ms/step - loss: 0.0494 - acc: 0.9842 - val_loss: 0.1871 - val_acc: 0.9315\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 37s 254ms/step - loss: 0.0573 - acc: 0.9795 - val_loss: 0.1166 - val_acc: 0.9593\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 35s 239ms/step - loss: 0.0443 - acc: 0.9859 - val_loss: 0.0987 - val_acc: 0.9715\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 38s 259ms/step - loss: 0.0514 - acc: 0.9814 - val_loss: 0.1158 - val_acc: 0.9516\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 36s 245ms/step - loss: 0.0397 - acc: 0.9867 - val_loss: 0.1145 - val_acc: 0.9553\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 36s 247ms/step - loss: 0.0455 - acc: 0.9839 - val_loss: 0.1270 - val_acc: 0.9472\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 37s 256ms/step - loss: 0.0270 - acc: 0.9923 - val_loss: 0.0832 - val_acc: 0.9637\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 38s 257ms/step - loss: 0.0390 - acc: 0.9887 - val_loss: 0.1224 - val_acc: 0.9472\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 34s 234ms/step - loss: 0.0291 - acc: 0.9908 - val_loss: 0.1148 - val_acc: 0.9715\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 35s 238ms/step - loss: 0.0285 - acc: 0.9932 - val_loss: 0.1399 - val_acc: 0.9516\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 37s 250ms/step - loss: 0.0255 - acc: 0.9934 - val_loss: 0.0755 - val_acc: 0.9797\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 35s 240ms/step - loss: 0.0244 - acc: 0.9932 - val_loss: 0.0910 - val_acc: 0.9675\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 34s 235ms/step - loss: 0.0263 - acc: 0.9912 - val_loss: 0.1322 - val_acc: 0.9597\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 35s 243ms/step - loss: 0.0185 - acc: 0.9964 - val_loss: 0.1926 - val_acc: 0.9390\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 36s 250ms/step - loss: 0.0249 - acc: 0.9912 - val_loss: 0.0947 - val_acc: 0.9675\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 34s 236ms/step - loss: 0.0143 - acc: 0.9974 - val_loss: 0.1039 - val_acc: 0.9637\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 36s 248ms/step - loss: 0.0133 - acc: 0.9974 - val_loss: 0.1039 - val_acc: 0.9675\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 35s 237ms/step - loss: 0.0165 - acc: 0.9961 - val_loss: 0.1106 - val_acc: 0.9593\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 36s 248ms/step - loss: 0.0104 - acc: 0.9983 - val_loss: 0.1270 - val_acc: 0.9556\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 35s 237ms/step - loss: 0.0109 - acc: 0.9985 - val_loss: 0.1043 - val_acc: 0.9675\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 35s 240ms/step - loss: 0.0126 - acc: 0.9974 - val_loss: 0.1063 - val_acc: 0.9634\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 35s 237ms/step - loss: 0.0101 - acc: 0.9987 - val_loss: 0.1155 - val_acc: 0.9677\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 35s 239ms/step - loss: 0.0104 - acc: 0.9981 - val_loss: 0.0935 - val_acc: 0.9675\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 35s 243ms/step - loss: 0.0130 - acc: 0.9970 - val_loss: 0.1612 - val_acc: 0.9472\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 37s 252ms/step - loss: 0.0093 - acc: 0.9985 - val_loss: 0.1056 - val_acc: 0.9556\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 34s 235ms/step - loss: 0.0072 - acc: 0.9991 - val_loss: 0.1097 - val_acc: 0.9675\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 36s 247ms/step - loss: 0.0053 - acc: 0.9998 - val_loss: 0.1329 - val_acc: 0.9634\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 35s 243ms/step - loss: 0.0051 - acc: 0.9998 - val_loss: 0.1587 - val_acc: 0.9553\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 35s 241ms/step - loss: 0.0050 - acc: 0.9996 - val_loss: 0.1378 - val_acc: 0.9516\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 35s 239ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0602 - val_acc: 0.9715\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 36s 244ms/step - loss: 0.0088 - acc: 0.9981 - val_loss: 0.1414 - val_acc: 0.9634\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 35s 242ms/step - loss: 0.0041 - acc: 0.9998 - val_loss: 0.1379 - val_acc: 0.9597\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir = 'data\\\\train'\n",
    "test_dir = 'data\\\\test'\n",
    "\n",
    "dim = 224\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim, dim, 3)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(5e-5),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 146,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9410 images belonging to 2 classes.\n",
      "Found 366 images belonging to 2 classes.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,662,338\n",
      "Trainable params: 1,662,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "  6/146 [>.............................] - ETA: 30s - loss: 0.5853 - acc: 0.7656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\Image.py:918: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  'to RGBA images')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45/146 [========>.....................] - ETA: 24s - loss: 0.4760 - acc: 0.8472"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bikas\\Anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:756: UserWarning: Corrupt EXIF data.  Expecting to read 12 bytes but only got 10. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 35s 236ms/step - loss: 0.4292 - acc: 0.8515 - val_loss: 0.5544 - val_acc: 0.7258\n",
      "Epoch 2/50\n",
      "146/146 [==============================] - 33s 223ms/step - loss: 0.3046 - acc: 0.8810 - val_loss: 0.3081 - val_acc: 0.8699\n",
      "Epoch 3/50\n",
      "146/146 [==============================] - 31s 215ms/step - loss: 0.2231 - acc: 0.9193 - val_loss: 0.2187 - val_acc: 0.9268\n",
      "Epoch 4/50\n",
      "146/146 [==============================] - 34s 235ms/step - loss: 0.1694 - acc: 0.9411 - val_loss: 0.1989 - val_acc: 0.9315\n",
      "Epoch 5/50\n",
      "146/146 [==============================] - 34s 230ms/step - loss: 0.1416 - acc: 0.9548 - val_loss: 0.1412 - val_acc: 0.9309\n",
      "Epoch 6/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.1222 - acc: 0.9572 - val_loss: 0.2564 - val_acc: 0.9106\n",
      "Epoch 7/50\n",
      "146/146 [==============================] - 33s 229ms/step - loss: 0.1137 - acc: 0.9565 - val_loss: 0.2229 - val_acc: 0.9234\n",
      "Epoch 8/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.1124 - acc: 0.9617 - val_loss: 0.1580 - val_acc: 0.9472\n",
      "Epoch 9/50\n",
      "146/146 [==============================] - 32s 222ms/step - loss: 0.0995 - acc: 0.9653 - val_loss: 0.1375 - val_acc: 0.9431\n",
      "Epoch 10/50\n",
      "146/146 [==============================] - 34s 230ms/step - loss: 0.0916 - acc: 0.9694 - val_loss: 0.1302 - val_acc: 0.9516\n",
      "Epoch 11/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0789 - acc: 0.9728 - val_loss: 0.1253 - val_acc: 0.9431\n",
      "Epoch 12/50\n",
      "146/146 [==============================] - 32s 222ms/step - loss: 0.0940 - acc: 0.9675 - val_loss: 0.1181 - val_acc: 0.9593\n",
      "Epoch 13/50\n",
      "146/146 [==============================] - 32s 222ms/step - loss: 0.0798 - acc: 0.9730 - val_loss: 0.2436 - val_acc: 0.9073\n",
      "Epoch 14/50\n",
      "146/146 [==============================] - 33s 229ms/step - loss: 0.0706 - acc: 0.9754 - val_loss: 0.0803 - val_acc: 0.9675\n",
      "Epoch 15/50\n",
      "146/146 [==============================] - 33s 227ms/step - loss: 0.0623 - acc: 0.9771 - val_loss: 0.1056 - val_acc: 0.9553\n",
      "Epoch 16/50\n",
      "146/146 [==============================] - 33s 227ms/step - loss: 0.0665 - acc: 0.9760 - val_loss: 0.1337 - val_acc: 0.9516\n",
      "Epoch 17/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.0558 - acc: 0.9801 - val_loss: 0.1420 - val_acc: 0.9512\n",
      "Epoch 18/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.0561 - acc: 0.9816 - val_loss: 0.1058 - val_acc: 0.9512\n",
      "Epoch 19/50\n",
      "146/146 [==============================] - 33s 223ms/step - loss: 0.0466 - acc: 0.9844 - val_loss: 0.1369 - val_acc: 0.9476\n",
      "Epoch 20/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.0523 - acc: 0.9799 - val_loss: 0.1134 - val_acc: 0.9593\n",
      "Epoch 21/50\n",
      "146/146 [==============================] - 33s 225ms/step - loss: 0.0468 - acc: 0.9842 - val_loss: 0.1660 - val_acc: 0.9390\n",
      "Epoch 22/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.0478 - acc: 0.9824 - val_loss: 0.1361 - val_acc: 0.9597\n",
      "Epoch 23/50\n",
      "146/146 [==============================] - 34s 231ms/step - loss: 0.0393 - acc: 0.9867 - val_loss: 0.0848 - val_acc: 0.9715\n",
      "Epoch 24/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.0484 - acc: 0.9829 - val_loss: 0.1866 - val_acc: 0.9228\n",
      "Epoch 25/50\n",
      "146/146 [==============================] - 32s 219ms/step - loss: 0.0391 - acc: 0.9876 - val_loss: 0.0824 - val_acc: 0.9718\n",
      "Epoch 26/50\n",
      "146/146 [==============================] - 33s 229ms/step - loss: 0.0384 - acc: 0.9861 - val_loss: 0.2136 - val_acc: 0.9268\n",
      "Epoch 27/50\n",
      "146/146 [==============================] - 32s 220ms/step - loss: 0.0310 - acc: 0.9897 - val_loss: 0.1003 - val_acc: 0.9553\n",
      "Epoch 28/50\n",
      "146/146 [==============================] - 35s 239ms/step - loss: 0.0302 - acc: 0.9889 - val_loss: 0.1348 - val_acc: 0.9516\n",
      "Epoch 29/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0262 - acc: 0.9912 - val_loss: 0.0985 - val_acc: 0.9593\n",
      "Epoch 30/50\n",
      "146/146 [==============================] - 33s 226ms/step - loss: 0.0228 - acc: 0.9923 - val_loss: 0.2151 - val_acc: 0.9146\n",
      "Epoch 31/50\n",
      "146/146 [==============================] - 32s 218ms/step - loss: 0.0244 - acc: 0.9929 - val_loss: 0.1349 - val_acc: 0.9476\n",
      "Epoch 32/50\n",
      "146/146 [==============================] - 35s 237ms/step - loss: 0.0199 - acc: 0.9929 - val_loss: 0.1154 - val_acc: 0.9715\n",
      "Epoch 33/50\n",
      "146/146 [==============================] - 32s 217ms/step - loss: 0.0355 - acc: 0.9861 - val_loss: 0.0750 - val_acc: 0.9715\n",
      "Epoch 34/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0189 - acc: 0.9942 - val_loss: 0.1035 - val_acc: 0.9637\n",
      "Epoch 35/50\n",
      "146/146 [==============================] - 35s 237ms/step - loss: 0.0206 - acc: 0.9921 - val_loss: 0.1261 - val_acc: 0.9634\n",
      "Epoch 36/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0178 - acc: 0.9953 - val_loss: 0.0946 - val_acc: 0.9675\n",
      "Epoch 37/50\n",
      "146/146 [==============================] - 33s 224ms/step - loss: 0.0175 - acc: 0.9946 - val_loss: 0.1847 - val_acc: 0.9476\n",
      "Epoch 38/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.0197 - acc: 0.9929 - val_loss: 0.0556 - val_acc: 0.9756\n",
      "Epoch 39/50\n",
      "146/146 [==============================] - 34s 233ms/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.1744 - val_acc: 0.9553\n",
      "Epoch 40/50\n",
      "146/146 [==============================] - 32s 221ms/step - loss: 0.0119 - acc: 0.9976 - val_loss: 0.0707 - val_acc: 0.9677\n",
      "Epoch 41/50\n",
      "146/146 [==============================] - 34s 231ms/step - loss: 0.0111 - acc: 0.9974 - val_loss: 0.1255 - val_acc: 0.9553\n",
      "Epoch 42/50\n",
      "146/146 [==============================] - 32s 217ms/step - loss: 0.0113 - acc: 0.9961 - val_loss: 0.0958 - val_acc: 0.9675\n",
      "Epoch 43/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0823 - val_acc: 0.9677\n",
      "Epoch 44/50\n",
      "146/146 [==============================] - 33s 228ms/step - loss: 0.0135 - acc: 0.9968 - val_loss: 0.1312 - val_acc: 0.9593\n",
      "Epoch 45/50\n",
      "146/146 [==============================] - 34s 232ms/step - loss: 0.0112 - acc: 0.9970 - val_loss: 0.1584 - val_acc: 0.9472\n",
      "Epoch 46/50\n",
      "146/146 [==============================] - 33s 225ms/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.1666 - val_acc: 0.9593\n",
      "Epoch 47/50\n",
      "146/146 [==============================] - 33s 226ms/step - loss: 0.0078 - acc: 0.9981 - val_loss: 0.1221 - val_acc: 0.9516\n",
      "Epoch 48/50\n",
      "146/146 [==============================] - 33s 225ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.1357 - val_acc: 0.9715\n",
      "Epoch 49/50\n",
      "146/146 [==============================] - 35s 239ms/step - loss: 0.0089 - acc: 0.9968 - val_loss: 0.1737 - val_acc: 0.9472\n",
      "Epoch 50/50\n",
      "146/146 [==============================] - 34s 234ms/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.1197 - val_acc: 0.9637\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_dir = 'data\\\\train'\n",
    "test_dir = 'data\\\\test'\n",
    "\n",
    "dim = 128\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (dim, dim),\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(dim, dim, 3)))\n",
    "model.add(layers.MaxPool2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(1e-4),\n",
    "              loss=losses.categorical_crossentropy,\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 146,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=31\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Emotion_detection.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
